"""Fix stupid file naming issue.

Revision ID: b7e0935213d5
Revises: 916e4599f92d
Create Date: 2018-02-23 05:37:59.636484

"""

# revision identifiers, used by Alembic.
revision = 'b7e0935213d5'
down_revision = '916e4599f92d'

from alembic import op
import sqlalchemy as sa


import os
import re
import tqdm
import settings
import shutil

from sqlalchemy import Table

from sqlalchemy import Column
from sqlalchemy import BigInteger
from sqlalchemy import Integer
from sqlalchemy import Text
from sqlalchemy import Float
from sqlalchemy import Boolean
from sqlalchemy import DateTime
from sqlalchemy import Interval
from sqlalchemy import ForeignKey
from sqlalchemy import PrimaryKeyConstraint
from sqlalchemy import UniqueConstraint
from sqlalchemy.orm import relationship
from sqlalchemy.schema import UniqueConstraint

import datetime
from sqlalchemy.types import Enum
import sqlalchemy_jsonfield

from sqlalchemy.ext.compiler import compiles
from sqlalchemy.orm.session import Session

# This is craptacularly retarded. Sqlite is retarded
# see https://bitbucket.org/zzzeek/sqlalchemy/issues/2074/map-biginteger-type-to-integer-to-allow
@compiles(BigInteger, 'sqlite')
def bi_c(element, compiler, **kw):
	return "INTEGER"


dlstate_enum   = Enum('new', 'fetching', 'processing', 'complete', 'error', 'removed', 'disabled', 'specialty_deferred', 'specialty_ready', 'not_set', name='dlstate_enum')

from sqlalchemy.ext.declarative import declarative_base
Base = declarative_base()


class ArtItem(Base):
	__versioned__ = {}

	__tablename__       = 'art_item'

	id                  = Column(BigInteger, primary_key = True, index = True)
	state               = Column(dlstate_enum, default='new', index=True, nullable=False)
	errno               = Column(Integer, default='0')

	artist_id           = Column(BigInteger, ForeignKey('scrape_targets.id'), nullable=False)
	release_meta        = Column(Text, nullable = False, index=True)

	fetchtime           = Column(DateTime, default=datetime.datetime.min)
	addtime             = Column(DateTime, default=datetime.datetime.utcnow)

	title               = Column(Text)
	content             = Column(Text)
	content_structured  = Column(sqlalchemy_jsonfield.JSONField())

	artist         = relationship("ScrapeTargets")
	files          = relationship("ArtFile")
	tags           = relationship("ArtTags")

	__table_args__ = (
		UniqueConstraint('artist_id', 'release_meta'),
		)


class ArtFile(Base):
	__tablename__     = 'art_file'
	id                = Column(BigInteger, primary_key = True, index = True)

	item_id           = Column(BigInteger, ForeignKey('art_item.id'), nullable=False)
	seqnum            = Column(Integer, default='0', nullable=False)
	file_meta         = Column(Text, default='')

	state             = Column(dlstate_enum, default='not_set')

	filename          = Column(Text)

	fspath            = Column(Text, nullable=False)

	__table_args__ = (
		UniqueConstraint('item_id', 'seqnum', 'file_meta'),
		)

class ArtTags(Base):
	__tablename__     = 'art_tag'
	id                = Column(BigInteger, primary_key = True, index = True)

	item_id           = Column(BigInteger, ForeignKey('art_item.id'), nullable=False)

	tag               = Column(Text)

	__table_args__ = (
		UniqueConstraint('item_id', 'tag'),
		)


# File table doesn't know anything about URLs, since they're kept in the
# WebPages table entirely.
class ScrapeTargets(Base):
	__tablename__ = 'scrape_targets'
	id              = Column(BigInteger, primary_key = True)
	site_name       = Column(Text,     nullable=False)
	artist_name     = Column(Text,     nullable=False, index=True)
	uploadeh        = Column(Boolean,  index = True, default=False, nullable=True)
	last_fetched    = Column(DateTime, nullable=False, default=datetime.datetime.min)

	extra_meta      = Column(sqlalchemy_jsonfield.JSONField())

	release_cnt     = Column(Integer, default='0')

	posts           = relationship("ArtItem")

	in_progress     = Column(Boolean, default=False)

	__table_args__ = (
		UniqueConstraint('site_name', 'artist_name'),
		)



class ScraperStatus(Base):
	__tablename__     = 'scraper_status'
	id                = Column(BigInteger, primary_key = True, index = True)

	site_name          = Column(Text, nullable=False, unique=True, index=True)

	next_run          = Column(DateTime, nullable=False, default=datetime.datetime.min)
	prev_run          = Column(DateTime, nullable=False, default=datetime.datetime.min)
	prev_run_time     = Column(Interval, nullable=False, default=datetime.timedelta(0))
	is_running        = Column(Boolean,  nullable=False, default=False)

	status_text       = Column(Text)




import sqlalchemy as sa
sa.orm.configure_mappers()


def upgrade():
	# ### commands auto generated by Alembic - please adjust! ###


	bind = op.get_bind()
	sess = Session(bind=bind)

	print("Bind:", bind)
	print("Sess:", sess)

	reg1 = re.compile(r'httpswww\.deviantart\.comdownload[0-9]*')
	reg2 = re.compile(r'httpsimg00\.deviantart\.net[0-9a-z]{14}')
	reg3 = re.compile(r'httpsorig00\.deviantart\.net[0-9a-z]{14}')


	if not 'da' in settings.settings:
		return
	if not "shortName" in settings.settings['da']:
		return

	to_fix_names = sess.query(ScrapeTargets).filter(ScrapeTargets.site_name == settings.settings['da']["shortName"]).all()
	print("Found %s artists" % len(to_fix_names))
	for name in tqdm.tqdm(to_fix_names, desc='Artists'):
		# print(name)
		for post in tqdm.tqdm(name.posts, desc='Files'):
			# print("	Post:", post)
			for file in post.files:
				fsp = file.fspath
				fsp = os.path.join(settings.settings["dldCtntPath"], fsp)
				if fsp and "/http" in fsp:
					dirp, fname = os.path.split(fsp)
					fixed = fname
					if reg1.match(fname):
						fixed = reg1.sub("", fname)
						# print("		File: ", (fname, fixed))
					if reg2.match(fname):
						fixed = reg2.sub("", fname)
						# print("		File: ", (fname, fixed))
					if reg3.match(fname):
						fixed = reg3.sub("", fname)
						# print("		File: ", (fname, fixed))

					if fixed != fname:
						newp = os.path.join(dirp, fixed)

						loop = 1
						base, ext = os.path.splitext(newp)

						# Only insert number if the old and new items exist. If the source file
						# is missing, assume the file has been moved, so don't bother.
						if os.path.exists(newp) and os.path.exists(fsp):
							while os.path.exists(newp):
								newp = "%s (%d)%s" % (base, loop, ext)
								loop += 1



						# if fqDlPath:
						# 	fqDlPath = [os.path.abspath(tmp) for tmp in fqDlPath if tmp]
						# 	fqDlPath = [os.path.relpath(tmp, settings["dldCtntPath"]) for tmp in fqDlPath if tmp]
						resp = os.path.relpath(newp, settings.settings["dldCtntPath"])
						file.fspath = newp
						if os.path.exists(fsp):
							shutil.move(fsp, newp)
						elif os.path.exists(newp):
							# already been moved, nothing to do.
							pass
						else:
							print("Missing file: ", fsp, resp, os.path.exists(fsp), os.path.exists(newp))
						# print("Should move:", (fsp, newp, resp))
	sess.commit()
	# ### end Alembic commands ###


def downgrade():
	# ### commands auto generated by Alembic - please adjust! ###
	pass
	# ### end Alembic commands ###
